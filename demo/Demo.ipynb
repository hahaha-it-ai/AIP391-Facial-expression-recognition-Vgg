{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 40, 40]             640\n",
      "       BatchNorm2d-2           [-1, 64, 40, 40]             128\n",
      "              ReLU-3           [-1, 64, 40, 40]               0\n",
      "         MaxPool2d-4           [-1, 64, 20, 20]               0\n",
      "            Conv2d-5          [-1, 128, 18, 18]         204,928\n",
      "       BatchNorm2d-6          [-1, 128, 18, 18]             256\n",
      "              ReLU-7          [-1, 128, 18, 18]               0\n",
      "         MaxPool2d-8            [-1, 128, 9, 9]               0\n",
      "            Conv2d-9            [-1, 256, 9, 9]          32,768\n",
      "      BatchNorm2d-10            [-1, 256, 9, 9]             512\n",
      "            ReLU6-11            [-1, 256, 9, 9]               0\n",
      "           Conv2d-12            [-1, 256, 9, 9]           2,304\n",
      "      BatchNorm2d-13            [-1, 256, 9, 9]             512\n",
      "            ReLU6-14            [-1, 256, 9, 9]               0\n",
      "           Conv2d-15            [-1, 128, 9, 9]          32,768\n",
      "    InvertedBlock-16            [-1, 128, 9, 9]               0\n",
      "           Conv2d-17            [-1, 256, 9, 9]          32,768\n",
      "      BatchNorm2d-18            [-1, 256, 9, 9]             512\n",
      "            ReLU6-19            [-1, 256, 9, 9]               0\n",
      "           Conv2d-20            [-1, 256, 9, 9]           2,304\n",
      "      BatchNorm2d-21            [-1, 256, 9, 9]             512\n",
      "            ReLU6-22            [-1, 256, 9, 9]               0\n",
      "           Conv2d-23            [-1, 128, 9, 9]          32,768\n",
      "    InvertedBlock-24            [-1, 128, 9, 9]               0\n",
      "        MaxPool2d-25            [-1, 128, 4, 4]               0\n",
      "           Conv2d-26            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-27            [-1, 512, 4, 4]           1,024\n",
      "            ReLU6-28            [-1, 512, 4, 4]               0\n",
      "           Conv2d-29            [-1, 512, 4, 4]           4,608\n",
      "      BatchNorm2d-30            [-1, 512, 4, 4]           1,024\n",
      "            ReLU6-31            [-1, 512, 4, 4]               0\n",
      "           Conv2d-32            [-1, 128, 4, 4]          65,536\n",
      "    InvertedBlock-33            [-1, 128, 4, 4]               0\n",
      "           Conv2d-34            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-35            [-1, 512, 4, 4]           1,024\n",
      "            ReLU6-36            [-1, 512, 4, 4]               0\n",
      "           Conv2d-37            [-1, 512, 4, 4]           4,608\n",
      "      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n",
      "            ReLU6-39            [-1, 512, 4, 4]               0\n",
      "           Conv2d-40            [-1, 128, 4, 4]          65,536\n",
      "    InvertedBlock-41            [-1, 128, 4, 4]               0\n",
      "        MaxPool2d-42            [-1, 128, 2, 2]               0\n",
      "           Linear-43                  [-1, 256]         131,328\n",
      "           Linear-44                  [-1, 128]          32,896\n",
      "           Linear-45                    [-1, 7]             903\n",
      "================================================================\n",
      "Total params: 784,263\n",
      "Trainable params: 784,263\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 6.62\n",
      "Params size (MB): 2.99\n",
      "Estimated Total Size (MB): 9.62\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "class InvertedBlock(nn.Module):\n",
    "    def __init__(self, squeeze=16, expand=64):\n",
    "\n",
    "        super(InvertedBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(squeeze, expand, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(expand),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            # Depthwise Convolution\n",
    "            nn.Conv2d(expand, expand, kernel_size=3, stride=1, padding=1, groups=expand, bias=False),\n",
    "            nn.BatchNorm2d(expand),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            # Pointwise Convolution + Linear projection\n",
    "            nn.Conv2d(expand, squeeze, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv(x)\n",
    "\n",
    "\n",
    "class VggFeatures(nn.Module):\n",
    "    def __init__(self, drop=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        def conv_bn(inp, oup, ks):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels=inp, out_channels=oup, kernel_size=ks, padding=1),\n",
    "                nn.BatchNorm2d(oup),\n",
    "                nn.ReLU(inplace=True)\n",
    "                )\n",
    "        def invert(squeeze, expand):\n",
    "            return InvertedBlock(squeeze, expand)\n",
    "        \n",
    "        self.layer1 = conv_bn(1, 64, 3)\n",
    "        self.layer2 = conv_bn(64, 128, 5)\n",
    "        self.layer3 = invert(128, 256)\n",
    "        self.layer4 = invert(128, 256)\n",
    "        self.layer5 = invert(128, 512)\n",
    "        self.layer6 = invert(128, 512)\n",
    "        self.lin1 = nn.Linear(128*2*2, 256)\n",
    "        self.lin2 = nn.Linear(256, 128)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "          \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        x = self.pool(x)\n",
    "        # print(x.shape)\n",
    "\n",
    "        x = x.view(-1, 128 * 2 * 2)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Vgg(VggFeatures):\n",
    "    def __init__(self, drop=0.2):\n",
    "        super().__init__(drop)\n",
    "        self.lin3 = nn.Linear(128, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = super().forward(x)\n",
    "        x = self.lin3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "from torchsummary import summary\n",
    "net = Vgg()\n",
    "net = net.eval()\n",
    "summary(net, (1, 40, 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self):\n",
    "        self.loss_train = []\n",
    "        self.loss_val = []\n",
    "\n",
    "        self.acc_train = []\n",
    "        self.acc_val = []\n",
    "\n",
    "    def get_logs(self):\n",
    "        return self.loss_train, self.loss_val, self.acc_train, self.acc_val\n",
    "\n",
    "    def restore_logs(self, logs):\n",
    "        self.loss_train, self.loss_val, self.acc_train, self.acc_val = logs\n",
    "\n",
    "    def save_plt(self, hps):\n",
    "        loss_path = os.path.join(hps['model_save_dir'], 'loss.jpg')\n",
    "        acc_path = os.path.join(hps['model_save_dir'], 'acc.jpg')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(self.acc_train, 'g', label='Training Acc')\n",
    "        plt.plot(self.acc_val, 'b', label='Validation Acc')\n",
    "        plt.title('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Acc')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.savefig(acc_path)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(self.loss_train, 'g', label='Training Loss')\n",
    "        plt.plot(self.loss_val, 'b', label='Validation Loss')\n",
    "        plt.title('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.savefig(loss_path)\n",
    "    def show_plt(self):\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(self.acc_train, 'g', label='Training Acc')\n",
    "        plt.plot(self.acc_val, 'b', label='Validation Acc')\n",
    "        plt.title('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Acc')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(self.loss_train, 'g', label='Training Loss')\n",
    "        plt.plot(self.loss_val, 'b', label='Validation Loss')\n",
    "        plt.title('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Restored!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "epoch = 158\n",
    "path = os.path.join('cp_demo', 'epoch_' + str(epoch))\n",
    "logger = Logger()\n",
    "checkpoint = torch.load(path, map_location=torch.device('cpu'))\n",
    "\n",
    "logger.restore_logs(checkpoint['logs'])\n",
    "net.load_state_dict(checkpoint['params'])\n",
    "print(\"Network Restored!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load the cascade\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "mu,st = 0,255\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(mu,), std=(st,))\n",
    "    ])\n",
    "\n",
    "lb = {0: \"angry\", 1: \"disgust\", 2: \"fear\", 3: \"happy\", 4: \"sad\", 5: \"surprise\", 6: \"neutral\"}\n",
    "\n",
    "def check(gray_face):\n",
    "    img = cv2.resize(gray_face, (40,40)).astype(np.float64)\n",
    "    img = Image.fromarray(img)\n",
    "    img = test_transform(img)\n",
    "    img.unsqueeze_(0)\n",
    "    outputs = net(img)\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "    return int(preds.data[0])\n",
    "# To capture video from webcam. \n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read the frame\n",
    "    _, img = cap.read()\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect the faces\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    # Draw the rectangle around each face\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = gray[y:y+h,x:x+w]\n",
    "        a = check(face)\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        img = cv2.putText(img, lb[a], (x, y), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                   1, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "    # Display\n",
    "    cv2.imshow('img', img)\n",
    "    # Stop if escape key is pressed\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k==27:\n",
    "        break\n",
    "# Release the VideoCapture object\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
